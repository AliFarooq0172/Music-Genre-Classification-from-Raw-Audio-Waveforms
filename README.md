# Music-Genre-Classification-from-Raw-Audio-Waveforms
Multi-Genre Music Classification Using Hybrid CNN-LSTM Architecture on Raw Audio Waveforms

Traditional music genre classification systems rely heavily on handcrafted features like MFCCs, spectral contrast, and chroma features. This project explores an end-to-end deep learning approach that processes raw audio waveforms directly, eliminating the need for manual feature engineering. By combining 1D CNNs (for local temporal patterns) with LSTMs (for sequential dependencies), the model learns hierarchical representations directly from time-domain audio signals, potentially capturing subtle genre characteristics that engineered features might miss.
